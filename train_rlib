from ray.tune.registry import register_env
from gym_ursina import make_env
import argparse
from ray.rllib.models import ModelCatalog
from models import rlib_model
from call_backs import MyCallBacks

parser = argparse.ArgumentParser(description='PPO')
parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
parser.add_argument('--max_grad_norm', type=float, default=0.5, help='Learning rate for discriminator')
parser.add_argument('--critic_loss_coeff', type=float, default=0.5, help='Learning rate for discriminator')
parser.add_argument('--entropy_coeff', type=float, default=0.01, help='Learning rate for discriminator')
parser.add_argument('--bs', type=int, default=1000, help='Batch size')
parser.add_argument('--ppo_epochs', type=int, default=5, help='Number of epochs')
parser.add_argument('--text_input_length', type=int, default=34, help='406 Number of features in text input')
parser.add_argument('--depth_map_length', type=int, default=0, help='361 Number of features in text input')
parser.add_argument('--action_direction_length', type=int, default=29, help='possible actions')
parser.add_argument('--max_action_length', type=int, default=10, help='the max action length')
parser.add_argument('--num_steps', type=int, default=2000, help='number of steps per epoch')
parser.add_argument('--test_steps', type=int, default=10000, help='number of steps per epoch')
parser.add_argument('--seed', type=int, default=7, help='seed to initialize libraries')
parser.add_argument('--max_iter', type=int, default=3000000, help='max number of steps')
parser.add_argument('--load_model', type=bool, default=False, help='load a pretrained model')
parser.add_argument('--compute_dynamic_stat', type=bool, default=True, help='collect the agents data in parallel')
parser.add_argument('--anneal_lr', type=bool, default= False, help='collect the agents data in parallel')
parser.add_argument('--parallel_workers_test', type=int, default=1, help='number of parallel agents')
parser.add_argument('--parallel_workers', type=int, default=2, help='number of parallel agents')
parser.add_argument('--envs_per_worker', type=int, default=2, help='number of parallel agents')
parser.add_argument('--sageMaker', type=bool, default=False, help='number of parallel agents')




if __name__ == '__main__':
    args = parser.parse_args()



    register_env("UrsinaGym", make_env)
    ModelCatalog.register_custom_model("rlib_model", rlib_model)

    config = {
    "framework": "torch",
    "num_workers": 2,
    "num_gpus_per_worker": 1/args.parallel_workers,
    "num_envs_per_worker": 2,
    "rollout_fragment_length": 100,
    "batch_mode": "complete_episodes",
    "train_batch_size": 1000,
    "gamma": 0.99,
    "lr": 0.0001,
    "env":"UrsinaGym",
    "env_config":{
        "obs_size":34,
        "mask_size":29,"min_size":75,
        "max_size":250,
        "is_teacher":True},
    "model": {
         "custom_model":"rlib_model",
         "custom_model_config": {
            "obs":args.text_input_length,
            "action_mask": args.action_direction_length,
            "hidden_layer":128},},
    "recreate_failed_workers":True,
    "restart_failed_sub_environments":True,
    "remote_worker_envs": True,
    "remote_env_batch_wait_ms": 1,
    "callbacks": MyCallBacks,
    }